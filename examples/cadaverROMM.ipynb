{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "Nath\\*, Mathis\\* et al. Using DeepLabCut for 3D markerless pose estimation during behavior across species.\n",
    "\n",
    "pre-print: https://www.biorxiv.org/content/10.1101/476531v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and parameters\n",
    "requires: 2 c-arm videos per run folder, \"training\" folder with 2D distorted marker exports in experiment root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import deeplabcut\n",
    "import pandas as pd\n",
    "import ruamel.yaml\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "wd=r\"E:\\Users\\Phil\\DeepLabCut\\dev\"\n",
    "vid_directory=r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\"\n",
    "csv_directory = os.path.join(vid_directory,\"training\")\n",
    "experimenter='Phil'\n",
    "markerlist = ['Body_ds1_crn',\n",
    "              'Body_ds2_int',\n",
    "              'Body_ds3_cdl',\n",
    "              'Body_vn1_crn',\n",
    "              'Body_vn2_int',\n",
    "              'Body_vn3_cdl',\n",
    "              'Body_acc',\n",
    "              'Scapula_acr',\n",
    "              'Scapula_spi',\n",
    "              'Scapula_vtb',\n",
    "              'Scapula_acc',\n",
    "              'Humerus_dpc',\n",
    "              'Humerus_ent',\n",
    "              'Humerus_ect',\n",
    "              'Humerus_acc',\n",
    "              'Ulna_olc',\n",
    "              'Ulna_int',\n",
    "              'Ulna_dst',\n",
    "              'Ulna_acc',\n",
    "              'Radius_prx',\n",
    "              'Radius_int',\n",
    "              'Radius_dst',\n",
    "              'Radius_acc',\n",
    "              'Teres_maj_prx',\n",
    "              'Teres_maj_dst',\n",
    "              'Biceps_prx',\n",
    "              'Biceps_dst']\n",
    "dotsize = 5\n",
    "corner2move2 = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rename c-arm videos with trial name for easier id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameVideos(directory,skip=\"\"):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and not re.search(skip,root):\n",
    "                run_name = root.split(\"\\\\\")[-1]\n",
    "                new_name = run_name+name.replace(\"era No.\",\"\")\n",
    "                old_path = os.path.join(root,name)\n",
    "                new_path = os.path.join(root,new_name)\n",
    "                os.rename(old_path,new_path)\n",
    "                vid_list.append(new_path)\n",
    "            else:\n",
    "                continue\n",
    "    return vid_list\n",
    "                \n",
    "vid_list = renameVideos(vid_directory,\"cals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create new project (1 per animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\"\n",
      "Created \"E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\"\n",
      "Created \"E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\training-datasets\"\n",
      "Created \"E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\dlc-models\"\n",
      "Creating the symbolic link of the video\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run1retpro1_90-35-4ms\\run1retpro1_90-35-4msCam1.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run1retpro1_90-35-4msCam1.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run1retpro1_90-35-4ms\\run1retpro1_90-35-4msCam2.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run1retpro1_90-35-4msCam2.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run3circles_90-35-4ms\\run3circles_90-35-4msCam1.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run3circles_90-35-4msCam1.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run3circles_90-35-4ms\\run3circles_90-35-4msCam2.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run3circles_90-35-4msCam2.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run4addabd_90-35-4ms\\run4addabd_90-35-4msCam1.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run4addabd_90-35-4msCam1.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run4addabd_90-35-4ms\\run4addabd_90-35-4msCam2.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run4addabd_90-35-4msCam2.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run5flexextLAR_90-35-4ms\\run5flexextLAR_90-35-4msCam1.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run5flexextLAR_90-35-4msCam1.avi\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat\\run5flexextLAR_90-35-4ms\\run5flexextLAR_90-35-4msCam2.avi to E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run5flexextLAR_90-35-4msCam2.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run1retpro1_90-35-4msCam1.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run1retpro1_90-35-4msCam2.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run3circles_90-35-4msCam1.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run3circles_90-35-4msCam2.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run4addabd_90-35-4msCam1.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run4addabd_90-35-4msCam2.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run5flexextLAR_90-35-4msCam1.avi\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\videos\\run5flexextLAR_90-35-4msCam2.avi\n",
      "Generated \"E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\config.yaml\"\n",
      "\n",
      "A new project with name 1_3_4_5_unenhanced-Phil-2019-09-30 is created at E:\\Users\\Phil\\DeepLabCut\\dev and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "task='1_3_4_5_unenhanced'\n",
    "# vid_list=[ vid_directory+r'\\run1retpro1_90-35-4ms\\run1retpro1_90-35-4msCam1.avi',\n",
    "#         vid_directory+r'\\run1retpro1_90-35-4ms\\run1retpro1_90-35-4msCam2.avi',\n",
    "#         vid_directory+r'\\run3circles_90-35-4ms\\run3circles_90-35-4msCam1.avi',\n",
    "#         vid_directory+r'\\run3circles_90-35-4ms\\run3circles_90-35-4msCam2.avi',\n",
    "#         vid_directory+r'\\run4addabd_90-35-4ms\\run4addabd_90-35-4msCam1.avi',\n",
    "#         vid_directory+r'\\run4addabd_90-35-4ms\\run4addabd_90-35-4msCam2.avi',\n",
    "#         vid_directory+r'\\run5flexextLAR_90-35-4ms\\run5flexextLAR_90-35-4msCam1.avi',\n",
    "#         vid_directory+r'\\run5flexextLAR_90-35-4ms\\run5flexextLAR_90-35-4msCam2.avi'\n",
    "#       ]\n",
    "path_config_file=deeplabcut.create_new_project(task,experimenter,vid_list, working_directory=wd,copy_videos=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Overwrite default bodyparts with XROMM marker list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "config = ruamel.yaml.load(open(path_config_file))\n",
    "config['bodyparts']=markerlist\n",
    "config['dotsize']=dotsize\n",
    "config['corner2move2']=[corner2move2,corner2move2]\n",
    "ruamel.yaml.round_trip_dump(config, sys.stdout)\n",
    "with open(path_config_file, 'w') as fp:\n",
    "    ruamel.yaml.round_trip_dump(config, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Extract frames from vid_list for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:08, 90.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 81.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 80.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 80.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 81.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:11, 71.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 26.67  seconds.\n",
      "Extracting and downsampling... 800  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:09, 80.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "deeplabcut.extract_frames(path_config_file, userfeedback=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Convert XMALab exports to DeepLabCut format\n",
    "No spaces in marker names, otherwise 2D export fails (more header columns than data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam1\\CollectedData_Phil.h5\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam2\\CollectedData_Phil.h5\n",
      "saved E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam2\\CollectedData_Phil.h5\n"
     ]
    }
   ],
   "source": [
    "run_names = np.unique(np.array([vid.split(\"\\\\\")[-2] for vid in vid_list]))\n",
    "labeled_data_path=os.path.join(path_config_file.split('config.yaml')[0],\"labeled-data\\\\\")\n",
    "\n",
    "def hflip(x_old, width):\n",
    "    x_flipped = width - 1 - x_old\n",
    "    return x_flipped\n",
    "\n",
    "def xmalab2dlc(run,csv_directory,labeled_data_path, width=1024, h_flip=False):  \n",
    "    ## import XMAlab 2D exports\n",
    "    df = pd.read_csv(csv_directory+\"\\\\\"+run+\".csv\", sep=',', header=0, dtype='float', na_values=' NaN ')\n",
    "    ## coerce data into DeepLabCut hierarchical format\n",
    "    df['frame_index']=df.index\n",
    "    df['scorer']=experimenter\n",
    "    df = df.melt(id_vars=['frame_index','scorer'])\n",
    "    new = df['variable'].str.rsplit(\"_\",n=2,expand=True)\n",
    "    df['variable'],df['cam'],df['coords'] = new[0], new[1], new[2]\n",
    "    df=df.rename(columns={'variable':'bodyparts'})\n",
    "    df['coords']=df['coords'].str.rstrip(\" \").str.lower()\n",
    "    if h_flip == True:\n",
    "        df['value'][df['coords']=='x']= df['value'][df['coords']=='x'].apply(lambda x:width-1-x)\n",
    "    df['bodyparts']=df['bodyparts'].str.lstrip(\" \").astype(\"category\")\n",
    "    df['bodyparts'].cat.set_categories(markerlist,inplace=True)\n",
    "    df['frame_index'] = ['labeled-data\\\\' + run+\"Cam\"+x[-1] + '\\\\img' + (f\"{y:03d}\") + '.png' for x, y in zip(df['cam'], df['frame_index'])]\n",
    "    newdf = df.pivot_table(columns=['scorer', 'bodyparts', 'coords'],index='frame_index',values='value',aggfunc='first',dropna=False)\n",
    "    newdf.index.name=None\n",
    "    ## go into frame folders and get frame index ##\n",
    "    extracted_frames = []\n",
    "    for root, dirs, files in os.walk(labeled_data_path):\n",
    "        for name in files:\n",
    "            if name.endswith(\".png\") and run in root:\n",
    "                camera_id = root.split(' ')[-1][-1]\n",
    "                frame_no = int(name.split('.')[0].replace('img',''))\n",
    "                new_name = 'labeled-data\\\\'+run+\"Cam\"+camera_id+'\\\\img' + (f\"{frame_no:03d}\") + '.png'\n",
    "                extracted_frames.append(new_name)\n",
    "\n",
    "    ## filter by list of extracted frames\n",
    "    df_extracted = newdf.filter(items=pd.Index(extracted_frames),axis=0)\n",
    "\n",
    "    ## split new df into cams 1 and 2\n",
    "    df1 = df_extracted.filter(like=run+\"Cam\"+\"1\",axis=0)\n",
    "    df2 = df_extracted.filter(like=run+\"Cam\"+\"2\",axis=0)\n",
    "\n",
    "    ## split new df into cams 1 and 2, export as h5 and csv\n",
    "    for x in [1,2]:\n",
    "        cam_name = run+\"Cam\"+str(x)\n",
    "        dfx = df_extracted.filter(like=cam_name,axis=0)\n",
    "        data_name = labeled_data_path+cam_name+\"\\\\CollectedData_\"+experimenter+\".h5\"\n",
    "        print(data_name)\n",
    "        dfx.to_hdf(data_name, 'df_with_missing', format='table', mode='w')\n",
    "        dfx.to_csv(data_name.split('.h5')[0]+'.csv')\n",
    "        print(\"saved \"+str(data_name))\n",
    "\n",
    "        \n",
    "for run in run_names:\n",
    "    xmalab2dlc(run,csv_directory,labeled_data_path, h_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Check substituted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Phil.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam1_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam1_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam2_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run1retpro1_90-35-4msCam2_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam1_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam1_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam2_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run3circles_90-35-4msCam2_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam1_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam1_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam2_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run4addabd_90-35-4msCam2_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam1_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam1_labeled.\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam2_labeled  already exists!\n",
      "They are stored in the following folder: E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\labeled-data\\run5flexextLAR_90-35-4msCam2_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "##UNCOMMENT 2 LINES TO MANUALLY LABEL WITH GUI\n",
    "# %gui wx\n",
    "# deeplabcut.label_frames(path_config_file)\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "#### 9. Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25],\n",
      "                [26]],\n",
      " 'all_joints_names': ['Body_ds1_crn',\n",
      "                      'Body_ds2_int',\n",
      "                      'Body_ds3_cdl',\n",
      "                      'Body_vn1_crn',\n",
      "                      'Body_vn2_int',\n",
      "                      'Body_vn3_cdl',\n",
      "                      'Body_acc',\n",
      "                      'Scapula_acr',\n",
      "                      'Scapula_spi',\n",
      "                      'Scapula_vtb',\n",
      "                      'Scapula_acc',\n",
      "                      'Humerus_dpc',\n",
      "                      'Humerus_ent',\n",
      "                      'Humerus_ect',\n",
      "                      'Humerus_acc',\n",
      "                      'Ulna_olc',\n",
      "                      'Ulna_int',\n",
      "                      'Ulna_dst',\n",
      "                      'Ulna_acc',\n",
      "                      'Radius_prx',\n",
      "                      'Radius_int',\n",
      "                      'Radius_dst',\n",
      "                      'Radius_acc',\n",
      "                      'Teres_maj_prx',\n",
      "                      'Teres_maj_dst',\n",
      "                      'Biceps_prx',\n",
      "                      'Biceps_dst'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_1_3_4_5_unenhancedSep30\\\\1_3_4_5_unenhanced_Phil95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\LabAdmin\\\\.conda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_1_3_4_5_unenhancedSep30\\\\Documentation_data-1_3_4_5_unenhanced_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 27,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'E:\\\\Users\\\\Phil\\\\DeepLabCut\\\\dev\\\\1_3_4_5_unenhanced-Phil-2019-09-30',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'E:\\\\Users\\\\Phil\\\\DeepLabCut\\\\dev\\\\1_3_4_5_unenhanced-Phil-2019-09-30\\\\dlc-models\\\\iteration-0\\\\1_3_4_5_unenhancedSep30-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with standard pose-dataset loader.\n",
      "WARNING:tensorflow:From C:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 50\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'E:\\\\Users\\\\Phil\\\\DeepLabCut\\\\dev\\\\1_3_4_5_unenhanced-Phil-2019-09-30\\\\dlc-models\\\\iteration-0\\\\1_3_4_5_unenhancedSep30-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26]], 'all_joints_names': ['Body_ds1_crn', 'Body_ds2_int', 'Body_ds3_cdl', 'Body_vn1_crn', 'Body_vn2_int', 'Body_vn3_cdl', 'Body_acc', 'Scapula_acr', 'Scapula_spi', 'Scapula_vtb', 'Scapula_acc', 'Humerus_dpc', 'Humerus_ent', 'Humerus_ect', 'Humerus_acc', 'Ulna_olc', 'Ulna_int', 'Ulna_dst', 'Ulna_acc', 'Radius_prx', 'Radius_int', 'Radius_dst', 'Radius_acc', 'Teres_maj_prx', 'Teres_maj_dst', 'Biceps_prx', 'Biceps_dst'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_1_3_4_5_unenhancedSep30\\\\1_3_4_5_unenhanced_Phil95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\LabAdmin\\\\.conda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_1_3_4_5_unenhancedSep30\\\\Documentation_data-1_3_4_5_unenhanced_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 27, 'pos_dist_thresh': 17, 'project_path': 'E:\\\\Users\\\\Phil\\\\DeepLabCut\\\\dev\\\\1_3_4_5_unenhanced-Phil-2019-09-30', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50 loss: 0.1687 lr: 0.005\n",
      "iteration: 100 loss: 0.0289 lr: 0.005\n",
      "iteration: 150 loss: 0.0266 lr: 0.005\n",
      "iteration: 200 loss: 0.0231 lr: 0.005\n",
      "iteration: 250 loss: 0.0245 lr: 0.005\n",
      "iteration: 300 loss: 0.0241 lr: 0.005\n",
      "iteration: 350 loss: 0.0221 lr: 0.005\n",
      "iteration: 400 loss: 0.0239 lr: 0.005\n",
      "iteration: 450 loss: 0.0213 lr: 0.005\n",
      "iteration: 500 loss: 0.0219 lr: 0.005\n",
      "iteration: 550 loss: 0.0228 lr: 0.005\n",
      "iteration: 600 loss: 0.0210 lr: 0.005\n",
      "iteration: 650 loss: 0.0198 lr: 0.005\n",
      "iteration: 700 loss: 0.0189 lr: 0.005\n",
      "iteration: 750 loss: 0.0180 lr: 0.005\n",
      "iteration: 800 loss: 0.0184 lr: 0.005\n",
      "iteration: 850 loss: 0.0178 lr: 0.005\n",
      "iteration: 900 loss: 0.0169 lr: 0.005\n",
      "iteration: 950 loss: 0.0182 lr: 0.005\n",
      "iteration: 1000 loss: 0.0181 lr: 0.005\n",
      "iteration: 1050 loss: 0.0159 lr: 0.005\n",
      "iteration: 1100 loss: 0.0159 lr: 0.005\n",
      "iteration: 1150 loss: 0.0170 lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=50,saveiters=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "videofile_path = [r'\\\\tsclient\\Downloads\\run1retpro'] #Enter a folder OR a list of videos to analyze.\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,[r'\\\\tsclient\\Downloads\\run1retpro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_labeled_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideotype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingsetindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFrames2plot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayedbodyparts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mp4v'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputframerate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestfolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_skeleton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrailpoints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplaycropped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "    Labels the bodyparts in a video. Make sure the video is already analyzed by the function 'analyze_video'\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    config : string\n",
       "        Full path of the config.yaml file as a string.\n",
       "\n",
       "    videos : list\n",
       "        A list of strings containing the full paths to videos for analysis or a path to the directory, where all the videos with same extension are stored.\n",
       "    \n",
       "    videotype: string, optional\n",
       "        Checks for the extension of the video in case the input to the video is a directory.\n",
       " Only videos with this extension are analyzed. The default is ``.avi``\n",
       "\n",
       "    shuffle : int, optional\n",
       "        Number of shuffles of training dataset. Default is set to 1.\n",
       "    \n",
       "    trainingsetindex: int, optional\n",
       "        Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml).\n",
       "     \n",
       "    filtered: bool, default false\n",
       "        Boolean variable indicating if filtered output should be plotted rather than frame-by-frame predictions. Filtered version can be calculated with deeplabcut.filterpredictions\n",
       "    \n",
       "    videotype: string, optional\n",
       "        Checks for the extension of the video in case the input is a directory.\n",
       "Only videos with this extension are analyzed. The default is ``.avi``\n",
       "\n",
       "    save_frames: bool\n",
       "        If true creates each frame individual and then combines into a video. This variant is relatively slow as\n",
       "        it stores all individual frames. However, it uses matplotlib to create the frames and is therefore much more flexible (one can set transparency of markers, crop, and easily customize).\n",
       "\n",
       "    Frames2plot: List of indices\n",
       "        If not None & save_frames=True then the frames corresponding to the index will be plotted. For example, Frames2plot=[0,11] will plot the first and the 12th frame.\n",
       "        \n",
       "    delete: bool\n",
       "        If true then the individual frames created during the video generation will be deleted.\n",
       "\n",
       "    displayedbodyparts: list of strings, optional\n",
       "        This select the body parts that are plotted in the video. Either ``all``, then all body parts\n",
       "        from config.yaml are used orr a list of strings that are a subset of the full list.\n",
       "        E.g. ['hand','Joystick'] for the demo Reaching-Mackenzie-2018-08-30/config.yaml to select only these two body parts.\n",
       "\n",
       "    codec: codec for labeled video. Options see http://www.fourcc.org/codecs.php [depends on your ffmpeg installation.]\n",
       "    \n",
       "    outputframerate: positive number, output frame rate for labeled video (only available for the mode with saving frames.) By default: None, which results in the original video rate.\n",
       "    \n",
       "    destfolder: string, optional\n",
       "        Specifies the destination folder that was used for storing analysis data (default is the path of the video).\n",
       "        \n",
       "    draw_skeleton: bool\n",
       "        If ``True`` adds a line connecting the body parts making a skeleton on on each frame. The body parts to be connected and the color of these connecting lines are specified in the config file. By default: ``False``\n",
       "    \n",
       "    trailpoints: int\n",
       "        Number of revious frames whose body parts are plotted in a frame (for displaying history). Default is set to 0.\n",
       "    \n",
       "    displaycropped: bool, optional\n",
       "        Specifies whether only cropped frame is displayed (with labels analyzed therein), or the original frame with the labels analyzed in the cropped subset.\n",
       "    \n",
       "    Examples\n",
       "    --------\n",
       "    If you want to create the labeled video for only 1 video\n",
       "    >>> deeplabcut.create_labeled_video('/analysis/project/reaching-task/config.yaml',['/analysis/project/videos/reachingvideo1.avi'])\n",
       "    --------\n",
       "\n",
       "    If you want to create the labeled video for only 1 video and store the individual frames\n",
       "    >>> deeplabcut.create_labeled_video('/analysis/project/reaching-task/config.yaml',['/analysis/project/videos/reachingvideo1.avi'],save_frames=True)\n",
       "    --------\n",
       "\n",
       "    If you want to create the labeled video for multiple videos\n",
       "    >>> deeplabcut.create_labeled_video('/analysis/project/reaching-task/config.yaml',['/analysis/project/videos/reachingvideo1.avi','/analysis/project/videos/reachingvideo2.avi'])\n",
       "    --------\n",
       "\n",
       "    If you want to create the labeled video for all the videos (as .avi extension) in a directory.\n",
       "    >>> deeplabcut.create_labeled_video('/analysis/project/reaching-task/config.yaml',['/analysis/project/videos/'])\n",
       "\n",
       "    --------\n",
       "    If you want to create the labeled video for all the videos (as .mp4 extension) in a directory.\n",
       "    >>> deeplabcut.create_labeled_video('/analysis/project/reaching-task/config.yaml',['/analysis/project/videos/'],videotype='mp4')\n",
       "\n",
       "    --------\n",
       "\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\labadmin\\.conda\\envs\\dlc-windowsgpu\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,['/videos/video3.avi']) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
