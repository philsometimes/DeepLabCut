{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import deeplabcut\n",
    "import pandas as pd\n",
    "import ruamel.yaml\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "path_config_file = r\"C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\config.yaml\"\n",
    "\n",
    "# wd=r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\"\n",
    "possum_megavids=[r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c1_11Apr.mp4\",\n",
    "               r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c2_11Apr.mp4\"]\n",
    "experimenter=\"Phil\"\n",
    "\n",
    "\n",
    "hdf_path=r\"C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-diff\\labeled-data\\11Apr_diff\\machinelabels-iter0.h5\"\n",
    "\n",
    "bodyparts = ['Body_ds1_crn_cam1',\n",
    "             'Body_ds1_crn_cam2',\n",
    "             'Body_ds2_int_cam1',\n",
    "             'Body_ds2_int_cam2',\n",
    "             'Body_ds3_cdl_cam1',\n",
    "             'Body_ds3_cdl_cam2',\n",
    "             'Body_vn1_crn_cam1',\n",
    "             'Body_vn1_crn_cam2',\n",
    "             'Body_vn2_int_cam1',\n",
    "             'Body_vn2_int_cam2',\n",
    "             'Body_vn3_cdl_cam1',\n",
    "             'Body_vn3_cdl_cam2',\n",
    "             'Scapula_acr_cam1',\n",
    "             'Scapula_acr_cam2',\n",
    "             'Scapula_spi_cam1',\n",
    "             'Scapula_spi_cam2',\n",
    "             'Scapula_vtb_cam1',\n",
    "             'Scapula_vtb_cam2',\n",
    "             'Humerus_dpc_cam1',\n",
    "             'Humerus_dpc_cam2',\n",
    "             'Humerus_ent_cam1',\n",
    "             'Humerus_ent_cam2',\n",
    "             'Humerus_ect_cam1',\n",
    "             'Humerus_ect_cam2',\n",
    "             'Ulna_olc_cam1',\n",
    "             'Ulna_olc_cam2',\n",
    "             'Ulna_int_cam1',\n",
    "             'Ulna_int_cam2',\n",
    "             'Ulna_dst_cam1',\n",
    "             'Ulna_dst_cam2',\n",
    "             'Radius_prx_cam1',\n",
    "             'Radius_prx_cam2',\n",
    "             'Radius_int_cam1',\n",
    "             'Radius_int_cam2',\n",
    "             'Radius_dst_cam1',\n",
    "             'Radius_dst_cam2',\n",
    "             'Teres_maj_prx_cam1',\n",
    "             'Teres_maj_prx_cam2',\n",
    "             'Teres_maj_dst_cam1',\n",
    "             'Teres_maj_dst_cam2',\n",
    "             'Biceps_prx_cam1',\n",
    "             'Biceps_prx_cam2',\n",
    "             'Biceps_dst_cam1',\n",
    "             'Biceps_dst_cam2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new project and extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\videos\"\n",
      "Created \"\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\labeled-data\"\n",
      "Created \"\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\training-datasets\"\n",
      "Created \"\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\dlc-models\"\n",
      "Creating the symbolic link of the video\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c1_11Apr.mp4 to \\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\videos\\c1_11Apr.mp4\n",
      "Created the symlink of Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c2_11Apr.mp4 to \\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\videos\\c2_11Apr.mp4\n",
      "\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\videos\\c1_11Apr.mp4\n",
      "\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\videos\\c2_11Apr.mp4\n",
      "Generated \"\\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\possum101_11Apr-Phil-2020-04-13\\config.yaml\"\n",
      "\n",
      "A new project with name possum101_11Apr-Phil-2020-04-13 is created at \\\\rcstore02.rc.fas.harvard.edu\\spierce_lab\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "task='possum101_11Apr'\n",
    "path_config_file=deeplabcut.create_new_project(task,experimenter,possum_megavids, working_directory=wd, videotype='.mp4', copy_videos=False) \n",
    "%matplotlib inline\n",
    "deeplabcut.extract_frames(path_config_file, userfeedback=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "        \n",
    "def scanDir(directory, extension='avi', filters=[], filter_out=True, verbose=False):\n",
    "    file_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.lower().endswith(extension):\n",
    "                filename = os.path.join(root, name)\n",
    "                if verbose == True:\n",
    "                    print(\"Found file with extension .\"+ extension + \": \" + filename)\n",
    "                file_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    if len(filters) != 0:\n",
    "        if filter_out==True:\n",
    "            for string in filters:\n",
    "                file_list = [file for file in file_list if not re.search(string, file)]\n",
    "        else:\n",
    "            for string in filters:\n",
    "                file_list = [file for file in file_list if re.search(string, file)]\n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "        \n",
    "def vidToPngs(video_path, output_dir=None, indices_to_match=[], name_from_folder=True):\n",
    "    frame_index = 0\n",
    "    frame_counter = 0\n",
    "    if name_from_folder:\n",
    "        out_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    else:\n",
    "        out_name = 'img'\n",
    "    if output_dir==None:\n",
    "        out_dir = os.path.join(os.path.dirname(video_path),out_name)\n",
    "    else:\n",
    "        out_dir = output_dir\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame_counter += 1\n",
    "        if ret == True:\n",
    "            if indices_to_match and not frame_index in indices_to_match:\n",
    "                frame_index += 1\n",
    "                continue\n",
    "            else:\n",
    "                png_name = out_name+str(frame_index).zfill(4)+'.png'\n",
    "                png_path = os.path.join(out_dir, png_name)\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.imwrite(png_path, frame)\n",
    "                frame_counter = 0                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                frame_index += 1\n",
    "        else: \n",
    "            break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def matchFrames(extracted_dir):\n",
    "    extracted_files = scanDir(extracted_dir, extension='png') \n",
    "    extracted_indices = [int(os.path.splitext(os.path.basename(png))[0][3:].lstrip('0')) for png in extracted_files]\n",
    "    unique_indices = []\n",
    "    unique_indices = [index for index in extracted_indices if not index in unique_indices]\n",
    "    result = sorted(unique_indices)\n",
    "    return result   \n",
    "\n",
    "def extractMatchedFrames(indices, output_dir = None, src_vids=[]):\n",
    "    extracted_frames = []\n",
    "    for video in src_vids:\n",
    "        out_name = os.path.splitext(os.path.basename(video))[0]+'_matched'\n",
    "        if output_dir is not None:\n",
    "            output = output_dir\n",
    "        else:\n",
    "            output = os.path.join(os.path.dirname(video),out_name)\n",
    "        vidToPngs(video, output, indices_to_match=indices, name_from_folder=False)\n",
    "        extracted_frames.append(output)\n",
    "    return extracted_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdf_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fec7b3c17bfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mextracted_frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0msplitDlc2Xma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbodyparts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hdf_path' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def spliceXma2Dlc(substitute_video,project_path,csv_path, frame_indices):\n",
    "    substitute_name = os.path.splitext(os.path.basename(substitute_video))[0]\n",
    "    substitute_data_relpath = os.path.join(\"labeled-data\",substitute_name)\n",
    "    substitute_data_abspath = os.path.join(project_path,substitute_data_relpath)\n",
    "\n",
    "    df=pd.read_csv(csv_path,sep=',',header=0,dtype='float',na_values='NaN')\n",
    "    names = df.columns.values\n",
    "    parts = [name.rsplit('_',1)[0] for name in names]\n",
    "    parts_unique = []\n",
    "    for part in parts:\n",
    "        if not part in parts_unique:\n",
    "            parts_unique.append(part)\n",
    "    df['frame_index']=[os.path.join(substitute_data_relpath,'img'+str(index).zfill(4)+'.png') for index in frame_indices]\n",
    "    df['scorer']=experimenter\n",
    "    df = df.melt(id_vars=['frame_index','scorer'])\n",
    "    new = df['variable'].str.rsplit(\"_\",n=1,expand=True)\n",
    "    df['variable'],df['coords'] = new[0], new[1]\n",
    "    df=df.rename(columns={'variable':'bodyparts'})\n",
    "    df['coords']=df['coords'].str.rstrip(\" \").str.lower()\n",
    "    cat_type = pd.api.types.CategoricalDtype(categories=parts_unique,ordered=True)\n",
    "    df['bodyparts']=df['bodyparts'].str.lstrip(\" \").astype(cat_type)\n",
    "    newdf = df.pivot_table(columns=['scorer', 'bodyparts', 'coords'],index='frame_index',values='value',aggfunc='first',dropna=False)\n",
    "    newdf.index.name=None\n",
    "    ##export\n",
    "    if not os.path.exists(substitute_data_abspath):\n",
    "        os.mkdir(substitute_data_abspath)\n",
    "    data_name = os.path.join(substitute_data_abspath,(\"CollectedData_\"+experimenter+\".h5\"))\n",
    "    newdf.to_hdf(data_name, 'df_with_missing', format='table', mode='w')\n",
    "    newdf.to_csv(data_name.split('.h5')[0]+'.csv')\n",
    "    print(\"saved \"+str(data_name))\n",
    "    return substitute_data_abspath, parts_unique\n",
    "\n",
    "\n",
    "def splitDlc2Xma(hdf_path, bodyparts):\n",
    "    bodyparts_XY = []\n",
    "    for part in bodyparts:\n",
    "        bodyparts_XY.append(part+'_X')\n",
    "        bodyparts_XY.append(part+'_Y')\n",
    "    df=pd.read_hdf(hdf_path)\n",
    "    # extracted_frames= [index for index in df.index]\n",
    "    df = df.reset_index().melt(id_vars=['index'])\n",
    "    df = df[df['coords'] != 'likelihood']\n",
    "    df['id'] = df['bodyparts']+'_'+df['coords'].str.upper()\n",
    "    df[['index','value','id']]\n",
    "    df = df.pivot(index='index',columns='id',values='value')\n",
    "    extracted_frames = [index.split('\\\\')[-1] for index in df.index]\n",
    "    df = df.reindex(columns=bodyparts_XY)\n",
    "    df.to_csv(os.path.splitext(hdf_path)[0]+'_split'+'.csv',index=False)\n",
    "    return extracted_frames\n",
    "\n",
    "splitDlc2Xma(hdf_path, bodyparts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdf_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9f2d258d096>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhdf_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hdf_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import ruamel.yaml\n",
    "\n",
    "\n",
    "def updateConfig(path_config_file, videos=[],bodyparts=[],corner2move2=512):\n",
    "    config = ruamel.yaml.load(open(path_config_file))\n",
    "    if videos:\n",
    "        video_sets={video:{\"crop\":\"0, 1024, 0, 1024\"} for video in videos}\n",
    "        config['video_sets']=video_sets\n",
    "    if bodyparts:\n",
    "        config['bodyparts']=bodyparts\n",
    "    config['corner2move2']=[corner2move2,corner2move2]\n",
    "    ruamel.yaml.round_trip_dump(config, sys.stdout)\n",
    "    with open(path_config_file, 'w') as fp:\n",
    "        ruamel.yaml.round_trip_dump(config, fp)\n",
    "        fp.close()\n",
    "    return path_config_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digitize extracted frames in xmalab, then take marker IDs from output csv and convert digitized data to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-black\\labeled-data\\11Apr_black\\CollectedData_Phil.h5\n",
      "done!\n",
      "Task: possum101_11Apr\n",
      "scorer: Phil\n",
      "date: Apr13\n",
      "project_path: C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-black\n",
      "video_sets:\n",
      "  Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\11Apr_black.mp4:\n",
      "    crop: 0, 1024, 0, 1024\n",
      "bodyparts:\n",
      "- Body_ds1_crn_cam1\n",
      "- Body_ds1_crn_cam2\n",
      "- Body_ds2_int_cam1\n",
      "- Body_ds2_int_cam2\n",
      "- Body_ds3_cdl_cam1\n",
      "- Body_ds3_cdl_cam2\n",
      "- Body_vn1_crn_cam1\n",
      "- Body_vn1_crn_cam2\n",
      "- Body_vn2_int_cam1\n",
      "- Body_vn2_int_cam2\n",
      "- Body_vn3_cdl_cam1\n",
      "- Body_vn3_cdl_cam2\n",
      "- Scapula_acr_cam1\n",
      "- Scapula_acr_cam2\n",
      "- Scapula_spi_cam1\n",
      "- Scapula_spi_cam2\n",
      "- Scapula_vtb_cam1\n",
      "- Scapula_vtb_cam2\n",
      "- Humerus_dpc_cam1\n",
      "- Humerus_dpc_cam2\n",
      "- Humerus_ent_cam1\n",
      "- Humerus_ent_cam2\n",
      "- Humerus_ect_cam1\n",
      "- Humerus_ect_cam2\n",
      "- Ulna_olc_cam1\n",
      "- Ulna_olc_cam2\n",
      "- Ulna_int_cam1\n",
      "- Ulna_int_cam2\n",
      "- Ulna_dst_cam1\n",
      "- Ulna_dst_cam2\n",
      "- Radius_prx_cam1\n",
      "- Radius_prx_cam2\n",
      "- Radius_int_cam1\n",
      "- Radius_int_cam2\n",
      "- Radius_dst_cam1\n",
      "- Radius_dst_cam2\n",
      "- Teres_maj_prx_cam1\n",
      "- Teres_maj_prx_cam2\n",
      "- Teres_maj_dst_cam1\n",
      "- Teres_maj_dst_cam2\n",
      "- Biceps_prx_cam1\n",
      "- Biceps_prx_cam2\n",
      "- Biceps_dst_cam1\n",
      "- Biceps_dst_cam2\n",
      "start: 0\n",
      "stop: 1\n",
      "numframes2pick: 20\n",
      "skeleton:\n",
      "- - bodypart1\n",
      "  - bodypart2\n",
      "- - objectA\n",
      "  - bodypart3\n",
      "skeleton_color: black\n",
      "pcutoff: 0.1\n",
      "dotsize: 12\n",
      "alphavalue: 0.7\n",
      "colormap: jet\n",
      "TrainingFraction:\n",
      "- 0.95\n",
      "iteration: 0\n",
      "resnet: 50\n",
      "snapshotindex: -1\n",
      "batch_size: 8\n",
      "cropping: false\n",
      "x1: 0\n",
      "x2: 640\n",
      "y1: 277\n",
      "y2: 624\n",
      "corner2move2:\n",
      "- 512\n",
      "- 512\n",
      "move2corner: true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LabAdmin\\\\Documents\\\\Phil\\\\DeepLabCut\\\\dev\\\\possum101_11Apr-Phil-2020-04-13-black\\\\config.yaml'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute_video = r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\11Apr_black.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "xma_csv_path = r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c1and2_11Apr_matched_xmalab2D.csv\"\n",
    "project_path = os.path.dirname(path_config_file)\n",
    "extracted_dir = os.path.join(project_path,\"labeled-data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##get matching frames from merged video \n",
    "frame_indices = matchFrames(extracted_dir)\n",
    "spliced_folder, bodyparts = spliceXma2Dlc(substitute_video,project_path,xma_csv_path,frame_indices)\n",
    "\n",
    "extractMatchedFrames(frame_indices, output_dir = spliced_folder, src_vids=[substitute_video])\n",
    "\n",
    "##then remove separate cameras from project and insert new folder with merged video and extracted frames\n",
    "updateConfig(path_config_file, videos=[substitute_video],bodyparts=bodyparts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check imported labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Phil.\n",
      "They are stored in the following folder: C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-black\\labeled-data\\11Apr_black_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LabAdmin\\\\.conda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\__init__.py'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.__file__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\training-datasets\\iteration-0\\UnaugmentedDataSet_possum101_11AprApr13  already exists!\n",
      "C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\dlc-models\\iteration-0\\possum101_11AprApr13-trainset95shuffle1  already exists!\n",
      "C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\dlc-models\\iteration-0\\possum101_11AprApr13-trainset95shuffle1/train  already exists!\n",
      "C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\dlc-models\\iteration-0\\possum101_11AprApr13-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file, augmenter_type=\"imgaug\")\n",
    "trainposeconfigfile,testposeconfigfile,snapshotfolder=deeplabcut.return_train_network_path(path_config_file,1,0.95)\n",
    "cfg_dlc=deeplabcut.auxiliaryfunctions.read_plainconfig(trainposeconfigfile)\n",
    "\n",
    "cfg_dlc['scale_jitter_lo']= 0.5\n",
    "cfg_dlc['scale_jitter_up']=1.5\n",
    "\n",
    "cfg_dlc['augmentationprobability']=.5\n",
    "cfg_dlc['batch_size']=1 #pick that as large as your GPU can handle it\n",
    "cfg_dlc['elastic_transform']=True\n",
    "cfg_dlc['rotation']=180\n",
    "cfg_dlc['grayscale']=False\n",
    "cfg_dlc['hist_eq']=True\n",
    "cfg_dlc['fliplr']=True\n",
    "cfg_dlc['covering']=True\n",
    "cfg_dlc['motion_blur'] = True\n",
    "cfg_dlc['optimizer'] =\"adam\"\n",
    "cfg_dlc['dataset_type']='imgaug'\n",
    "cfg_dlc['multi_step']=[[1e-4, 7500], [5*1e-5, 12000], [1e-5, 50000], [5e-6, 200000]]\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(trainposeconfigfile,cfg_dlc)\n",
    "\n",
    "# deeplabcut.create_training_model_comparison(path_config_file,num_shuffles=1,net_types=['resnet_50'],augmenter_types=['default','imgaug'])\n",
    "\n",
    "\n",
    "# \tprint(\"EVALUATE\")\n",
    "# \tdeeplabcut.evaluate_network(path_config_file, Shuffles=[shuffle],plotting=True)\n",
    "\n",
    "# \tprint(\"Analyze Video\")\n",
    "\n",
    "# \tvideofile_path = os.path.join(os.getcwd(),'openfield-Pranav-2018-10-30','videos','m3v1mp4.mp4')\n",
    "\n",
    "# \tdeeplabcut.analyze_videos(path_config_file, [videofile_path], shuffle=shuffle)\n",
    "\n",
    "# \tprint(\"Create Labeled Video and plot\")\n",
    "# \tdeeplabcut.create_labeled_video(path_config_file,[videofile_path], shuffle=shuffle)\n",
    "# \tdeeplabcut.plot_trajectories(path_config_file,[videofile_path], shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN NETWORK 0\n",
      "The training datafile  C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\dlc-models\\iteration-0\\possum101_11AprApr13-trainset95shuffle0\\train\\pose_cfg.yaml  is not present.\n",
      "Probably, the training dataset for this specific shuffle index was not created.\n",
      "Try with a different shuffle/trainingsetfraction or use function 'create_training_dataset' to create a new trainingdataset with this shuffle index.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\LabAdmin\\\\Documents\\\\Phil\\\\DeepLabCut\\\\dev\\\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\\\dlc-models\\\\iteration-0\\\\possum101_11AprApr13-trainset95shuffle0\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-806aeb127c1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TRAIN NETWORK\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LabAdmin\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_yaml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mstart_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_yaml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#switch to folder of config_yaml (for logging)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0msetup_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\LabAdmin\\\\Documents\\\\Phil\\\\DeepLabCut\\\\dev\\\\possum101_11Apr-Phil-2020-04-13-AUGdiff\\\\dlc-models\\\\iteration-0\\\\possum101_11AprApr13-trainset95shuffle0\\\\train'"
     ]
    }
   ],
   "source": [
    "for shuffle in [0,1]:\n",
    "\tprint(\"TRAIN NETWORK\", shuffle)\n",
    "\tdeeplabcut.train_network(path_config_file, shuffle=shuffle,saveiters=10000,displayiters=200,maxiters=5,max_snapshots_to_keep=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "#### 9. Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=10,saveiters=10000, maxiters=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = r\"C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-diff\\config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(path_config_file,[r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\11Apr_diff.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap ['Z:\\\\lab\\\\NSF forelimb project\\\\Phil_lab\\\\dlc-data-swap\\\\11Apr_diff.mp4']\n",
      "Loading  Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\11Apr_diff.mp4 and data.\n",
      "7904\n",
      "Duration of video [s]:  263.47 , recorded with  30.0 fps!\n",
      "Overall # of frames:  7904 with cropped frame dimensions:  1024 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7904/7904 [01:15<00:00, 104.84it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,[r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\11Apr_diff.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,[r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\11Apr_diff.mp4\"],outlieralgorithm='jump', extractionalgorithm='kmeans', automatic=True, epsilon=30, comparisonbodyparts=['Ulna_olc_cam1','Ulna_dst_cam1','Radius_prx_cam1','Radius_dst_cam1','Humerus_ent_cam1','Humerus_ect_cam1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\labeled-data\\\\c1_11AprCam1\\CollectedData_Phil.h5\n",
      "saved C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\labeled-data\\\\c1_11AprCam2\\CollectedData_Phil.h5\n",
      "saved C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\labeled-data\\\\c2_11AprCam1\\CollectedData_Phil.h5\n",
      "saved C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\labeled-data\\\\c2_11AprCam2\\CollectedData_Phil.h5\n"
     ]
    }
   ],
   "source": [
    "def xmalab2dlc(run,csv_path,labeled_data_path, width=1024, h_flip=False):  \n",
    "    ## import XMAlab 2D exports\n",
    "    df = pd.read_csv(csv_path, sep=',', header=0, dtype='float', na_values=' NaN ')\n",
    "    ## coerce data into DeepLabCut hierarchical format\n",
    "    df['frame_index']=df.index\n",
    "    df['scorer']=experimenter\n",
    "    df = df.melt(id_vars=['frame_index','scorer'])\n",
    "    new = df['variable'].str.rsplit(\"_\",n=2,expand=True)\n",
    "    df['variable'],df['cam'],df['coords'] = new[0], new[1], new[2]\n",
    "    df=df.rename(columns={'variable':'bodyparts'})\n",
    "    df['coords']=df['coords'].str.rstrip(\" \").str.lower()\n",
    "    if h_flip == True:\n",
    "        df['value'][df['coords']=='x']= df['value'][df['coords']=='x'].apply(lambda x:width-1-x)\n",
    "    df['bodyparts']=df['bodyparts'].str.lstrip(\" \").astype(\"category\")\n",
    "    df['bodyparts'].cat.set_categories(markerlist,inplace=True)\n",
    "    df['frame_index'] = ['labeled-data\\\\' + run+\"Cam\"+x[-1] + '\\\\img' + (f\"{y:03d}\") + '.png' for x, y in zip(df['cam'], df['frame_index'])]\n",
    "    newdf = df.pivot_table(columns=['scorer', 'bodyparts', 'coords'],index='frame_index',values='value',aggfunc='first',dropna=False)\n",
    "    newdf.index.name=None\n",
    "    ## go into frame folders and get frame index ##\n",
    "    extracted_frames = []\n",
    "    for root, dirs, files in os.walk(labeled_data_path):\n",
    "        for name in files:\n",
    "            if name.endswith(\".png\") and run in root:\n",
    "                camera_id = root.split(' ')[-1][-1]\n",
    "                frame_no = int(name.split('.')[0].replace('img',''))\n",
    "                new_name = 'labeled-data\\\\'+run+\"Cam\"+camera_id+'\\\\img' + (f\"{frame_no:03d}\") + '.png'\n",
    "                extracted_frames.append(new_name)\n",
    "\n",
    "    ## filter by list of extracted frames\n",
    "    df_extracted = newdf.filter(items=pd.Index(extracted_frames),axis=0)\n",
    "\n",
    "    ## split new df into cams 1 and 2\n",
    "    df1 = df_extracted.filter(like=run+\"Cam\"+\"1\",axis=0)\n",
    "    df2 = df_extracted.filter(like=run+\"Cam\"+\"2\",axis=0)\n",
    "\n",
    "    ## split new df into cams 1 and 2, export as h5 and csv\n",
    "    for x in [1,2]:\n",
    "        cam_name = run+\"Cam\"+str(x)\n",
    "        dfx = df_extracted.filter(like=cam_name,axis=0)\n",
    "        data_name = labeled_data_path+cam_name+\"\\\\CollectedData_\"+experimenter+\".h5\"\n",
    "        dfx.to_hdf(data_name, 'df_with_missing', format='table', mode='w')\n",
    "        dfx.to_csv(data_name.split('.h5')[0]+'.csv')\n",
    "        print(\"saved \"+str(data_name))\n",
    "        \n",
    "run_names = ['c1_11Apr','c2_11Apr']\n",
    "labeled_data_path = r\"C:\\Users\\LabAdmin\\Documents\\Phil\\DeepLabCut\\dev\\possum101_11Apr-Phil-2020-04-13-separate\\labeled-data\\\\\"\n",
    "csv_path = r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\Ex\\11Apr18.LaiRegnault.SEP101.LS.biceps_teres_lat\\c1and2_11Apr_matched_xmalab2D.csv\"\n",
    "markerlist = ['Body_ds1_crn_cam1',\n",
    "'Body_ds1_crn_cam2',\n",
    "'Body_ds2_int_cam1',\n",
    "'Body_ds2_int_cam2',\n",
    "'Body_ds3_cdl_cam1',\n",
    "'Body_ds3_cdl_cam2',\n",
    "'Body_vn1_crn_cam1',\n",
    "'Body_vn1_crn_cam2',\n",
    "'Body_vn2_int_cam1',\n",
    "'Body_vn2_int_cam2',\n",
    "'Body_vn3_cdl_cam1',\n",
    "'Body_vn3_cdl_cam2',\n",
    "'Scapula_acr_cam1',\n",
    "'Scapula_acr_cam2',\n",
    "'Scapula_spi_cam1',\n",
    "'Scapula_spi_cam2',\n",
    "'Scapula_vtb_cam1',\n",
    "'Scapula_vtb_cam2',\n",
    "'Humerus_dpc_cam1',\n",
    "'Humerus_dpc_cam2',\n",
    "'Humerus_ent_cam1',\n",
    "'Humerus_ent_cam2',\n",
    "'Humerus_ect_cam1',\n",
    "'Humerus_ect_cam2',\n",
    "'Ulna_olc_cam1',\n",
    "'Ulna_olc_cam2',\n",
    "'Ulna_int_cam1',\n",
    "'Ulna_int_cam2',\n",
    "'Ulna_dst_cam1',\n",
    "'Ulna_dst_cam2',\n",
    "'Radius_prx_cam1',\n",
    "'Radius_prx_cam2',\n",
    "'Radius_int_cam1',\n",
    "'Radius_int_cam2',\n",
    "'Radius_dst_cam1',\n",
    "'Radius_dst_cam2',\n",
    "'Teres_maj_prx_cam1',\n",
    "'Teres_maj_prx_cam2',\n",
    "'Teres_maj_dst_cam1',\n",
    "'Teres_maj_dst_cam2',\n",
    "'Biceps_prx_cam1',\n",
    "'Biceps_prx_cam2',\n",
    "'Biceps_dst_cam1',\n",
    "'Biceps_dst_cam2',]\n",
    "for run in run_names:\n",
    "    xmalab2dlc(run,csv_path,labeled_data_path, h_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Convert XMALab exports to DeepLabCut format\n",
    "No spaces in marker names, otherwise 2D export fails (more header columns than data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(path_config_file,vids_to_analyze, videotype='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,vids_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_outlier_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideotype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingsetindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlieralgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'jump'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomparisonbodyparts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_bound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextractionalgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautomatic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_resizewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopencv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavelabeled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestfolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "   Extracts the outlier frames in case, the predictions are not correct for a certain video from the cropped video running from\n",
       "   start to stop as defined in config.yaml.\n",
       "\n",
       "   Another crucial parameter in config.yaml is how many frames to extract 'numframes2extract'.\n",
       "\n",
       "   Parameter\n",
       "   ----------\n",
       "   config : string\n",
       "       Full path of the config.yaml file as a string.\n",
       "\n",
       "   videos : list\n",
       "       A list of strings containing the full paths to videos for analysis or a path to the directory, where all the videos with same extension are stored.\n",
       "\n",
       "   videotype: string, optional\n",
       "       Checks for the extension of the video in case the input to the video is a directory.\n",
       "Only videos with this extension are analyzed. The default is ``.avi``\n",
       "\n",
       "   shuffle : int, optional\n",
       "       The shufle index of training dataset. The extracted frames will be stored in the labeled-dataset for\n",
       "       the corresponding shuffle of training dataset. Default is set to 1\n",
       "\n",
       "   trainingsetindex: int, optional\n",
       "       Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml).\n",
       "\n",
       "   outlieralgorithm: 'fitting', 'jump', 'uncertain', or 'manual'\n",
       "       String specifying the algorithm used to detect the outliers. Currently, deeplabcut supports three methods + a manual GUI option. 'Fitting'\n",
       "       fits a Auto Regressive Integrated Moving Average model to the data and computes the distance to the estimated data. Larger distances than\n",
       "       epsilon are then potentially identified as outliers. The methods 'jump' identifies larger jumps than 'epsilon' in any body part; and 'uncertain'\n",
       "       looks for frames with confidence below p_bound. The default is set to ``jump``.\n",
       "\n",
       "   comparisonbodyparts: list of strings, optional\n",
       "       This select the body parts for which the comparisons with the outliers are carried out. Either ``all``, then all body parts\n",
       "       from config.yaml are used orr a list of strings that are a subset of the full list.\n",
       "       E.g. ['hand','Joystick'] for the demo Reaching-Mackenzie-2018-08-30/config.yaml to select only these two body parts.\n",
       "\n",
       "   p_bound: float between 0 and 1, optional\n",
       "       For outlieralgorithm 'uncertain' this parameter defines the likelihood below, below which a body part will be flagged as a putative outlier.\n",
       "\n",
       "   epsilon; float,optional\n",
       "       Meaning depends on outlieralgoritm. The default is set to 20 pixels.\n",
       "       For outlieralgorithm 'fitting': Float bound according to which frames are picked when the (average) body part estimate deviates from model fit\n",
       "       For outlieralgorithm 'jump': Float bound specifying the distance by which body points jump from one frame to next (Euclidean distance)\n",
       "\n",
       "   ARdegree: int, optional\n",
       "       For outlieralgorithm 'fitting': Autoregressive degree of ARIMA model degree. (Note we use SARIMAX without exogeneous and seasonal part)\n",
       "       see https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\n",
       "\n",
       "   MAdegree: int\n",
       "       For outlieralgorithm 'fitting': MovingAvarage degree of ARIMA model degree. (Note we use SARIMAX without exogeneous and seasonal part)\n",
       "       See https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\n",
       "\n",
       "   alpha: float\n",
       "       Significance level for detecting outliers based on confidence interval of fitted ARIMA model. Only the distance is used however.\n",
       "\n",
       "   extractionalgorithm : string, optional\n",
       "       String specifying the algorithm to use for selecting the frames from the identified putatative outlier frames. Currently, deeplabcut\n",
       "       supports either ``kmeans`` or ``uniform`` based selection (same logic as for extract_frames).\n",
       "       The default is set to``uniform``, if provided it must be either ``uniform`` or ``kmeans``.\n",
       "\n",
       "   automatic : bool, optional\n",
       "       Set it to True, if you want to extract outliers without being asked for user feedback.\n",
       "\n",
       "   cluster_resizewidth: number, default: 30\n",
       "       For k-means one can change the width to which the images are downsampled (aspect ratio is fixed).\n",
       "\n",
       "   cluster_color: bool, default: False\n",
       "       If false then each downsampled image is treated as a grayscale vector (discarding color information). If true, then the color channels are considered. This increases\n",
       "       the computational complexity.\n",
       "\n",
       "   opencv: bool, default: True\n",
       "       Uses openCV for loading & extractiong (otherwise moviepy (legacy))\n",
       "\n",
       "   savelabeled: bool, default: True\n",
       "       If true also saves frame with predicted labels in each folder. \n",
       "\n",
       "   destfolder: string, optional\n",
       "       Specifies the destination folder that was used for storing analysis data (default is the path of the video). \n",
       "\n",
       "   Examples\n",
       "   \n",
       "   Windows example for extracting the frames with default settings\n",
       "   >>> deeplabcut.extract_outlier_frames('C:\\myproject\\reaching-task\\config.yaml',['C:\\yourusername\\rig-95\\Videos\\reachingvideo1.avi'])\n",
       "   --------\n",
       "   for extracting the frames with default settings\n",
       "   >>> deeplabcut.extract_outlier_frames('/analysis/project/reaching-task/config.yaml',['/analysis/project/video/reachinvideo1.avi'])\n",
       "   --------\n",
       "   for extracting the frames with kmeans\n",
       "   >>> deeplabcut.extract_outlier_frames('/analysis/project/reaching-task/config.yaml',['/analysis/project/video/reachinvideo1.avi'],extractionalgorithm='kmeans')\n",
       "   --------\n",
       "   for extracting the frames with kmeans and epsilon = 5 pixels.\n",
       "   >>> deeplabcut.extract_outlier_frames('/analysis/project/reaching-task/config.yaml',['/analysis/project/video/reachinvideo1.avi'],epsilon = 5,extractionalgorithm='kmeans')\n",
       "   --------\n",
       "   \n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\labadmin\\.conda\\envs\\dlc-windowsgpu\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,vid_list) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\training-datasets\\iteration-1\\UnaugmentedDataSet_1_3_4_5_unenhancedSep30  already exists!\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\dlc-models\\iteration-1\\1_3_4_5_unenhancedSep30-trainset95shuffle1  already exists!\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\dlc-models\\iteration-1\\1_3_4_5_unenhancedSep30-trainset95shuffle1//train  already exists!\n",
      "E:\\Users\\Phil\\DeepLabCut\\dev\\1_3_4_5_unenhanced-Phil-2019-09-30\\dlc-models\\iteration-1\\1_3_4_5_unenhancedSep30-trainset95shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file, maxiters=200000, displayiters=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
